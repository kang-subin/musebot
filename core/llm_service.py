from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage
from config.settings import GEMINI_API_KEY, DEFAULT_LLM_MODEL


class LLMService:
    def __init__(self, model: str = None):
        self.model = model or DEFAULT_LLM_MODEL
        self.llm = ChatGoogleGenerativeAI(
            model=self.model,
            google_api_key=GEMINI_API_KEY,
            temperature=0.7
        )

    def run(self, prompt: str) -> str:
        try:
            messages = [HumanMessage(content=prompt)]
            # invoke() ì‚¬ìš© ê¶Œì¥
            response = self.llm.invoke(messages)
            return response.content  # contentê°€ str í˜•íƒœë¡œ ë°˜í™˜ë¨
        except Exception as e:
            return f"ğŸš¨ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
